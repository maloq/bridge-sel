{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "from mesh_utils import slice_mesh_with_fuse\n",
    "from visualisation import visualize_results, visualize_projected, visualize_results_mesh\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER_PATH = 'image_selection_data/P_1'\n",
    "IMG_FORMAT = '.JPG'\n",
    "POSES_FOLDER = 'poses'\n",
    "MESH_PATH = 'image_selection_data/decimated_centered_textured_mesh.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_info(camera_id, camera_info_path = \"cameras.json\"):\n",
    "    assert os.path.exists(camera_info_path), \"Camera file not found\" \n",
    "    with open(camera_info_path) as json_file:\n",
    "        cameras_info = json.load(json_file)\n",
    "\n",
    "    for i in cameras_info:\n",
    "        if cameras_info[i][\"id\"] == camera_id:\n",
    "            camera_info = cameras_info[i]\n",
    "        break\n",
    "    return camera_info\n",
    "\n",
    "\n",
    "def load_image_info(image_name):\n",
    "    image_path = os.path.join(IMG_FOLDER_PATH, image_name + IMG_FORMAT) \n",
    "    assert os.path.exists(image_path), \"Image not found\" \n",
    "\n",
    "    pose_path = os.path.join(POSES_FOLDER, image_name + '.json') \n",
    "    assert os.path.exists(pose_path), \"Pose file not found\" \n",
    "    with open(pose_path) as json_file:\n",
    "        pose_info = json.load(json_file)\n",
    "\n",
    "    camera_info = get_camera_info(pose_info[\"camera_id\"]) \n",
    "    return pose_info, camera_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'DJI_20240417190632_0129_Z'\n",
    "pose_info, camera_info = load_image_info(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_mesh(mesh_path, camera_matrix, rotation, center, img_height, img_width, vis=False):\n",
    "    pier = trimesh.load(mesh_path, force='mesh')\n",
    "    pier_cutted = slice_mesh_with_fuse(rotation, center, camera_matrix/10, int(img_height*2), int(img_width*2), pier)\n",
    "    if vis:     \n",
    "        meshes = []\n",
    "        world_xyz = trimesh.creation.axis()\n",
    "        meshes.append(world_xyz)\n",
    "        camera_xyz = trimesh.creation.axis()\n",
    "        camera_xyz.vertices = (np.matmul(rotation.transpose(), camera_xyz.vertices.transpose()) + center).transpose()\n",
    "        meshes.append(camera_xyz)\n",
    "        meshes.append(pier_cutted)\n",
    "        scene = trimesh.Scene(meshes)\n",
    "        scene.show('notebook')\n",
    "    return pier_cutted, original_indices\n",
    "\n",
    "def prepare_camera_and_pose_data(camera_info, pose_info):\n",
    "    camera_matrix = np.float64(camera_info[\"matrix\"])\n",
    "    distortion_coefficients = np.float64(camera_info[\"distortion_coefficients\"])\n",
    "    rotation = np.float64(pose_info[\"rotation\"]).reshape(3, 3)\n",
    "    center = np.float64(pose_info[\"center\"]).reshape(3, 1)\n",
    "    img_height = camera_info[\"height\"]\n",
    "    img_width = camera_info[\"width\"]\n",
    "    return camera_matrix, distortion_coefficients, rotation, center, img_height, img_width\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_camera_matrix, _distortion_coefficients, _rotation, _center, _img_height, _img_width = prepare_camera_and_pose_data(camera_info, pose_info)\n",
    "_pier_cutted, = load_and_prepare_mesh(MESH_PATH, _camera_matrix, _rotation, _center, _img_height, _img_width, vis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices_behind_camera(vertices, rotation, translation_cam):\n",
    "    vertices = np.array(vertices, dtype=np.float64)\n",
    "    rotation = np.array(rotation, dtype=np.float64)\n",
    "    translation_cam = np.array(translation_cam, dtype=np.float64).squeeze()\n",
    "\n",
    "    transform = np.eye(4, dtype=np.float64)\n",
    "    transform[:3, :3] = rotation\n",
    "    transform[:3, 3] = translation_cam\n",
    "    homogeneous_vertices = np.hstack((vertices, np.ones((vertices.shape[0], 1))))\n",
    "    camera_coords = np.dot(homogeneous_vertices, transform.T)\n",
    "    behind_camera = camera_coords[:, 2] < 0\n",
    "\n",
    "    return behind_camera\n",
    "\n",
    "\n",
    "def project_vertices(mesh, rotation, center, camera_matrix, distortion_coefficients):\n",
    "    translation_cam = (-rotation @ center).reshape(3, 1)\n",
    "    projected_vertices, _ = cv.projectPoints(mesh.vertices.view(np.ndarray).astype(np.float64),\n",
    "                                             np.float64(rotation), np.float64(translation_cam),\n",
    "                                             np.float64(camera_matrix),\n",
    "                                             np.float64(distortion_coefficients))\n",
    "    projected_vertices = projected_vertices.squeeze() #.astype(np.int64)\n",
    "    return projected_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_vertices = project_vertices(_pier_cutted, _rotation, _center, _camera_matrix, _distortion_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_projected(projected_vertices, (img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vertices(vertices, projected_vertices, img_height, img_width, rotation, center):\n",
    "    print(f\"Total vertices: {len((vertices))}\")\n",
    "    print(f\"Vertices in image coordinates shape: {projected_vertices.shape}\")\n",
    "    behind_camera = behind_camera = get_vertices_behind_camera(vertices, rotation, (-rotation @ center).reshape(3, 1))\n",
    "    in_front_of_camera = ~behind_camera\n",
    "\n",
    "    within_x_bounds = (projected_vertices[:, 0] >= 0) & (projected_vertices[:, 0] < img_width)\n",
    "    within_y_bounds = (projected_vertices[:, 1] >= 0) & (projected_vertices[:, 1] < img_height)\n",
    "    within_image_bounds = within_x_bounds & within_y_bounds\n",
    "    potentially_visible = in_front_of_camera & within_image_bounds\n",
    "\n",
    "    potentially_visible = within_image_bounds\n",
    "    print(f\"Vertices in front of camera: {np.sum(in_front_of_camera)}\")\n",
    "    print(f\"Vertices within image boundaries: {np.sum(within_image_bounds)}\")\n",
    "    print(f\"Potentially visible vertices: {np.sum(potentially_visible)}\")\n",
    "    potential_indices = np.where(potentially_visible)[0]      \n",
    "    return potential_indices\n",
    "\n",
    "def check_visibility(mesh, vertices, potential_indices, center, treshhold=0.01):\n",
    "\n",
    "    print('Total vertices', len(vertices))\n",
    "    vertices_projected = vertices[potential_indices]\n",
    "    print('Projected vertices', len(vertices_projected))\n",
    "\n",
    "    rays_directions = vertices_projected - center.squeeze()\n",
    "    distances = np.linalg.norm(rays_directions, axis=1)\n",
    "    rays_directions /= distances.reshape(-1, 1)\n",
    "    rays_origins = np.tile(center.squeeze(), (len(rays_directions), 1))\n",
    "\n",
    "    locations, index_ray, index_tri = mesh.ray.intersects_location(\n",
    "        ray_origins=rays_origins,\n",
    "        ray_directions=rays_directions,\n",
    "        multiple_hits=False\n",
    "    )\n",
    "\n",
    "    any_hit = mesh.ray.intersects_any(\n",
    "        ray_origins=rays_origins,\n",
    "        ray_directions=rays_directions\n",
    "    )\n",
    "\n",
    "    potential_indices_hits = np.where(any_hit)[0]\n",
    "    print('Ray hits',len(potential_indices_hits))\n",
    "\n",
    "    vertices_projected_hits = vertices_projected[potential_indices_hits]\n",
    "\n",
    "    ray_miss = np.abs(vertices_projected_hits - locations) # score to deside if vertice is visible\n",
    "    ray_miss = ray_miss < treshhold\n",
    "\n",
    "    visible = np.logical_and(ray_miss[:, 0], np.logical_and(ray_miss[:, 1], ray_miss[:, 2]))\n",
    "    print('Visible', sum(visible))\n",
    "\n",
    "    visible_indices = potential_indices[potential_indices_hits[visible]]\n",
    "    visible_vertices = vertices[visible_indices]\n",
    "    print('Visible vertices', len(visible_vertices))\n",
    "\n",
    "    vis_rays_origins = rays_origins[potential_indices_hits[visible]]\n",
    "    vis_rays_directions =  rays_directions[potential_indices_hits[visible]]\n",
    "    return visible_indices, vis_rays_origins, vis_rays_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vertices: 398\n",
      "Vertices in image coordinates shape: (398, 2)\n",
      "Vertices in front of camera: 398\n",
      "Vertices within image boundaries: 282\n",
      "Potentially visible vertices: 282\n",
      "Total vertices 398\n",
      "Projected vertices 282\n",
      "Ray hits 227\n",
      "Visible 88\n",
      "Visible vertices 88\n"
     ]
    }
   ],
   "source": [
    "vertices = _pier_cutted.vertices.view(np.ndarray).astype(np.float64)\n",
    "\n",
    "potential_indices = filter_vertices(vertices, projected_vertices, _img_height, _img_width, _rotation, _center)\n",
    "visible_indices, vis_rays_origins, vis_rays_directions = check_visibility(_pier_cutted, vertices, potential_indices, _center, treshhold=0.01)\n",
    "camera_position = _center.squeeze()\n",
    "\n",
    "visualize_results_rays(_pier_cutted,\n",
    "                       visible_indices,\n",
    "                       camera_position,\n",
    "                       _rotation, _center,  vis_rays_origins, vis_rays_directions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results_mesh(_pier_cutted, visible_indices, _rotation, _center, vis_rays_origins, vis_rays_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
